{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data_x_df = pd.read_csv('data_X.csv') ## features\n",
    "data_t_df = pd.read_csv('data_T.csv') ## labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total # of data point (features): (20433, 8)\n",
      "total # of data point (label)   : (20433, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"total # of data point (features): {}\".format(data_x_df.shape))\n",
    "print(\"total # of data point (label)   : {}\".format(data_t_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41</td>\n",
       "      <td>880</td>\n",
       "      <td>129</td>\n",
       "      <td>322</td>\n",
       "      <td>126</td>\n",
       "      <td>8.3252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21</td>\n",
       "      <td>7099</td>\n",
       "      <td>1106</td>\n",
       "      <td>2401</td>\n",
       "      <td>1138</td>\n",
       "      <td>8.3014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52</td>\n",
       "      <td>1467</td>\n",
       "      <td>190</td>\n",
       "      <td>496</td>\n",
       "      <td>177</td>\n",
       "      <td>7.2574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52</td>\n",
       "      <td>1274</td>\n",
       "      <td>235</td>\n",
       "      <td>558</td>\n",
       "      <td>219</td>\n",
       "      <td>5.6431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52</td>\n",
       "      <td>1627</td>\n",
       "      <td>280</td>\n",
       "      <td>565</td>\n",
       "      <td>259</td>\n",
       "      <td>3.8462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                  41          880             129   \n",
       "1    -122.22     37.86                  21         7099            1106   \n",
       "2    -122.24     37.85                  52         1467             190   \n",
       "3    -122.25     37.85                  52         1274             235   \n",
       "4    -122.25     37.85                  52         1627             280   \n",
       "\n",
       "   population  households  median_income  \n",
       "0         322         126         8.3252  \n",
       "1        2401        1138         8.3014  \n",
       "2         496         177         7.2574  \n",
       "3         558         219         5.6431  \n",
       "4         565         259         3.8462  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_x_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Shuffle and Split Data into Training and Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_feat_label(feats, label):\n",
    "    idx = np.random.permutation(feats.index)\n",
    "    feats_random = feats.reindex(idx)\n",
    "    label_random = label.reindex(idx)\n",
    "    \n",
    "    return feats_random, label_random\n",
    "\n",
    "def split_train_val(feats, label, train_ratio):\n",
    "    ## Shuffle\n",
    "    feats, label = shuffle_feat_label(feats, label)\n",
    "    \n",
    "    ## Number of data\n",
    "    num_total = feats.shape[0]\n",
    "    num_train = int(num_total * train_ratio)\n",
    "    num_valid = num_total - num_train\n",
    "    \n",
    "    ## Split and convert to numpy array\n",
    "    train_feats, train_label = feats.iloc[0:num_train].to_numpy(), label.iloc[0:num_train].to_numpy()\n",
    "    valid_feats, valid_label = feats.iloc[num_train:].to_numpy(), label.iloc[num_train:].to_numpy()\n",
    "    \n",
    "    return train_feats, train_label, valid_feats, valid_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of training   data: (16346, 8)\n",
      "# of validation data: (4087, 8)\n"
     ]
    }
   ],
   "source": [
    "train_x, train_t, valid_x, valid_t = split_train_val(data_x_df, data_t_df, 0.8)\n",
    "print(\"# of training   data: {}\".format(train_x.shape))\n",
    "print(\"# of validation data: {}\".format(valid_x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(x):\n",
    "    \"\"\"Do normalization on each column\"\"\"\n",
    "    mean = np.mean(x, axis=0)\n",
    "    std = np.std(x, axis=0)\n",
    "    norm_x = (x - mean) / std\n",
    "    \n",
    "    return norm_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = normalization(train_x)\n",
    "train_t = normalization(train_t)\n",
    "valid_x = normalization(valid_x)\n",
    "valid_t = normalization(valid_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel:\n",
    "    \"\"\"Implementation of Linear Regression Model\"\"\"\n",
    "    \n",
    "    def __init__(self, num_feat, M, basis=\"polynomial\", regularize=False, _lambda=None):\n",
    "        \n",
    "        self.num_feat = num_feat ## number of features\n",
    "        self.M = M ## order of basis function\n",
    "        self.basis = basis ## \"polynomial\", \"gaussian\"\n",
    "        self.regularize = regularize ## use regularization or not\n",
    "        self._lambda = _lambda ## hyperparameter for regularization term\n",
    "    \n",
    "    def combinations(self, iterable, r):\n",
    "        \"\"\"\n",
    "        Return the length-r combinations of a list of integers without duplicate ones\n",
    "        \n",
    "        Ex: combinations([0, 1, 2], 2) --> (0, 0) (0, 1) (0, 2) (1, 1) (1, 2) (2, 2)\n",
    "        \"\"\"\n",
    "        \n",
    "        pool = tuple(iterable)\n",
    "        n = len(pool)\n",
    "        if not n and r:\n",
    "            return\n",
    "        indices = [0] * r\n",
    "        yield tuple(pool[i] for i in indices)\n",
    "        while True:\n",
    "            for i in reversed(range(r)):\n",
    "                if indices[i] != n - 1:\n",
    "                    break\n",
    "            else:\n",
    "                return\n",
    "            indices[i:] = [indices[i] + 1] * (r - i)\n",
    "            yield tuple(pool[i] for i in indices)\n",
    "    \n",
    "    def polynomial_basis(self, x, order):\n",
    "        \"\"\"The polynomial basis function\"\"\"\n",
    "        \n",
    "        for idx, comb in enumerate(list(self.combinations(range(self.num_feat), order))):\n",
    "            product = np.prod(x[:, comb], axis=1) ## (16346, )\n",
    "            product = np.expand_dims(product, axis=1) ## (16346, 1)\n",
    "            \n",
    "            if idx == 0:\n",
    "                Phi_i = product\n",
    "            else:\n",
    "                Phi_i = np.hstack((Phi_i, product))\n",
    "                \n",
    "        return Phi_i\n",
    "    \n",
    "    def gaussian_basis(self, x, mu, sigma=0.05):\n",
    "        \"\"\"The Gaussian basis function\"\"\"\n",
    "        \n",
    "        return np.exp(-0.5 * ((x - mu) / sigma) ** 2)\n",
    "        \n",
    "    def transform_x(self, x):\n",
    "        \"\"\"Convert input with basis function, x->Phi(x)\"\"\"\n",
    "        \n",
    "        if self.basis.lower() == \"polynomial\":\n",
    "            Phi = np.ones((x.shape[0], 1)) ## (16346, 1)\n",
    "            for order in range(1, self.M + 1):\n",
    "                Phi_i = self.polynomial_basis(x, order)\n",
    "                Phi = np.hstack((Phi, Phi_i))\n",
    "                \n",
    "        elif self.basis.lower() == \"gaussian\":\n",
    "            Phi = np.ones((x.shape[0], 1)) ## (16346, 1)\n",
    "            for order in range(1, self.M + 1):\n",
    "                mu = order / (self.M + 1) ## design a mean value for the gaussian distribution\n",
    "                Phi_i = self.gaussian_basis(x, mu)\n",
    "                Phi = np.hstack((Phi, Phi_i))\n",
    "        \n",
    "        return Phi\n",
    "    \n",
    "    def train(self, train_x, train_t):\n",
    "        \"\"\"Fit the model on the training set\"\"\"\n",
    "        \n",
    "        if self.regularize: ## Solution: w = (lambda*I+Phi^T*Phi)^(-1)*Phi^T*t\n",
    "            Phi = self.transform_x(train_x)\n",
    "            I = np.eye(Phi.shape[1])\n",
    "            tmp = np.linalg.inv(self._lambda * I + np.dot(Phi.T, Phi))\n",
    "            tmp = np.dot(tmp, Phi.T)\n",
    "            w = np.dot(tmp, train_t)\n",
    "        \n",
    "        else: ## Solution: w = (Phi^T*Phi)^(-1)*Phi^T*t\n",
    "            Phi = self.transform_x(train_x)\n",
    "            tmp = np.linalg.inv(np.dot(Phi.T, Phi))\n",
    "            tmp = np.dot(tmp, Phi.T)\n",
    "            w = np.dot(tmp, train_t)\n",
    "        \n",
    "        return w\n",
    "    \n",
    "    def eval_rms(self, x, w, t):\n",
    "        \"\"\"Evaluate root mean square error\"\"\"\n",
    "        \n",
    "        Phi = self.transform_x(x)\n",
    "        y = np.dot(Phi, w)\n",
    "        rms = np.sqrt(np.mean((y - t) ** 2))\n",
    "        \n",
    "        return rms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.1 Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.1.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M = 1, train_rms: 0.60200, valid_rms: 0.60505\n",
      "M = 2, train_rms: 0.54713, valid_rms: 0.55658\n"
     ]
    }
   ],
   "source": [
    "## M = 1 ~ 2\n",
    "for m in range(1, 3):\n",
    "    model = RegressionModel(train_x.shape[1], m)\n",
    "    w = model.train(train_x, train_t)\n",
    "    \n",
    "    ## Evaluate RMS error on training set\n",
    "    train_rms = model.eval_rms(train_x, w, train_t)\n",
    "    \n",
    "    ## Evaluate RMS error on validation set\n",
    "    valid_rms = model.eval_rms(valid_x, w, valid_t)\n",
    "    \n",
    "    print(\"M = {}, train_rms: {:.5f}, valid_rms: {:.5f}\".format(m, train_rms, valid_rms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.1.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w0 = 6.438670126576729e-15\n",
      "w1 = -0.7441408063229755\n",
      "w2 = -0.7871754558585801\n",
      "w3 = 0.12795919867870248\n",
      "w4 = -0.16215679195756258\n",
      "w5 = 0.41894465526861807\n",
      "w6 = -0.3639789946593941\n",
      "w7 = 0.1464846059154457\n",
      "w8 = 0.6641478194873874\n",
      "\n",
      "The weight with maximum value is w8\n"
     ]
    }
   ],
   "source": [
    "model = RegressionModel(train_x.shape[1], 1)\n",
    "w = model.train(train_x, train_t)\n",
    "for idx, wi in enumerate(w.flatten()):\n",
    "    print(\"w{} = {}\".format(idx, wi))\n",
    "    \n",
    "print(\"\\nThe weight with maximum value is w{}\".format(np.argmax(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without feature 1, train_rms: 0.65197, valid_rms: 0.65645\n",
      "Without feature 2, train_rms: 0.65700, valid_rms: 0.66291\n",
      "Without feature 3, train_rms: 0.61271, valid_rms: 0.61434\n",
      "Without feature 4, train_rms: 0.60368, valid_rms: 0.60633\n",
      "Without feature 5, train_rms: 0.60594, valid_rms: 0.60917\n",
      "Without feature 6, train_rms: 0.61915, valid_rms: 0.62723\n",
      "Without feature 7, train_rms: 0.60250, valid_rms: 0.60596\n",
      "Without feature 8, train_rms: 0.78324, valid_rms: 0.79439\n"
     ]
    }
   ],
   "source": [
    "## Delete one feature at a time and see when which one is removed, the rms error is greatest,\n",
    "## then the feature is the most contributive one\n",
    "for i in range(train_x.shape[1]):\n",
    "    new_train_x = np.concatenate((train_x[:, :i], train_x[:, i + 1:]), axis=1) ## (16346, 7)\n",
    "    new_valid_x = np.concatenate((valid_x[:, :i], valid_x[:, i + 1:]), axis=1) ## (16346, 7)\n",
    "    \n",
    "    model = RegressionModel(new_train_x.shape[1], M=1)\n",
    "    w = model.train(new_train_x, train_t)\n",
    "    train_rms = model.eval_rms(new_train_x, w, train_t)\n",
    "    valid_rms = model.eval_rms(new_valid_x, w, valid_t)\n",
    "    \n",
    "    print(\"Without feature {}, train_rms: {:.5f}, valid_rms: {:.5f}\".format(i + 1, train_rms, valid_rms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.2 Maximum Likelihood Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.2.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M =  1, train_rms:   0.95876, valid_rms:       0.96147\n",
      "M =  2, train_rms:   0.98351, valid_rms:       0.98325\n",
      "M =  3, train_rms:   0.92702, valid_rms:       0.93159\n",
      "M =  4, train_rms:   0.92522, valid_rms:       0.91183\n",
      "M =  5, train_rms:   0.90463, valid_rms:       0.90941\n",
      "M =  6, train_rms:   0.88238, valid_rms:       0.87905\n",
      "M =  7, train_rms:   0.88527, valid_rms:       0.89028\n",
      "M =  8, train_rms:   0.87205, valid_rms:       0.87643\n",
      "M =  9, train_rms:   0.87575, valid_rms:       0.87266\n",
      "M = 10, train_rms:   0.86510, valid_rms:       0.87303\n",
      "M = 11, train_rms:   0.86259, valid_rms:       0.86671\n",
      "M = 12, train_rms:   0.86212, valid_rms:       0.86906\n",
      "M = 13, train_rms:   0.85737, valid_rms:       0.86629\n",
      "M = 14, train_rms:   0.85473, valid_rms:      11.71325\n",
      "M = 15, train_rms:   0.85388, valid_rms:      54.10811\n",
      "M = 16, train_rms:   0.85018, valid_rms:    3760.48644\n",
      "M = 17, train_rms:   0.84604, valid_rms:   10612.07434\n",
      "M = 18, train_rms:   0.84314, valid_rms:   23111.32806\n",
      "M = 19, train_rms:   0.83869, valid_rms:   53358.10631\n",
      "M = 20, train_rms:   0.83536, valid_rms:   15483.01912\n"
     ]
    }
   ],
   "source": [
    "## M = 1 ~ 20\n",
    "for m in range(1, 21):\n",
    "    model = RegressionModel(train_x.shape[1], m, basis=\"gaussian\")\n",
    "    w = model.train(train_x, train_t)\n",
    "    \n",
    "    ## Evaluate RMS error on training set\n",
    "    train_rms = model.eval_rms(train_x, w, train_t)\n",
    "    \n",
    "    ## Evaluate RMS error on validation set\n",
    "    valid_rms = model.eval_rms(valid_x, w, valid_t)\n",
    "    \n",
    "    print(\"M = {:2d}, train_rms: {:9.5f}, valid_rms: {:13.5f}\".format(m, train_rms, valid_rms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.2.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_n_fold(feats, label, n):\n",
    "    \"\"\"Split raw data into n fold, shuffle and do normalization\"\"\"\n",
    "    \n",
    "    ## Shuffle\n",
    "    feats, label = shuffle_feat_label(feats, label)\n",
    "    \n",
    "    ## Split data into n equal parts\n",
    "    fold_len = int(feats.shape[0] / n)\n",
    "    n_parts_x, n_parts_t = [], []\n",
    "    \n",
    "    for i in range(n):\n",
    "        if i == (n - 1):\n",
    "            start_idx, end_idx = i * fold_len, feats.shape[0]\n",
    "        else:\n",
    "            start_idx, end_idx = i * fold_len, (i + 1) * fold_len\n",
    "        \n",
    "        part_i_x = feats.iloc[start_idx:end_idx].to_numpy()\n",
    "        part_i_t = label.iloc[start_idx:end_idx].to_numpy()\n",
    "        n_parts_x.append(part_i_x)\n",
    "        n_parts_t.append(part_i_t)\n",
    "    \n",
    "    print(\"{} folds, fold lengths = {}\".format(n, [part_i.shape[0] for part_i in n_parts_x]))\n",
    "    \n",
    "    ## N folds\n",
    "    n_folds = []\n",
    "    for i in range(n):\n",
    "        ## x\n",
    "        train_x_i = np.concatenate(n_parts_x[:i] + n_parts_x[i + 1:])\n",
    "        valid_x_i = n_parts_x[i]\n",
    "        \n",
    "        ## t\n",
    "        train_t_i = np.concatenate(n_parts_t[:i] + n_parts_t[i + 1:])\n",
    "        valid_t_i = n_parts_t[i]\n",
    "        \n",
    "        ## Normalization\n",
    "        train_x_i = normalization(train_x_i)\n",
    "        train_t_i = normalization(train_t_i)\n",
    "        valid_x_i = normalization(valid_x_i)\n",
    "        valid_t_i = normalization(valid_t_i)\n",
    "        \n",
    "        fold_i = [train_x_i, valid_x_i, train_t_i, valid_t_i]\n",
    "        n_folds.append(fold_i)\n",
    "    \n",
    "    return n_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 folds, fold lengths = [4086, 4086, 4086, 4086, 4089]\n"
     ]
    }
   ],
   "source": [
    "n_folds = split_n_fold(data_x_df, data_t_df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold = 0, M =  1, train_rms:   0.96006, valid_rms:      0.95570\n",
      "Fold = 0, M =  2, train_rms:   0.98184, valid_rms:      0.98808\n",
      "Fold = 0, M =  3, train_rms:   0.92887, valid_rms:      0.92692\n",
      "Fold = 0, M =  4, train_rms:   0.92312, valid_rms:      0.92921\n",
      "Fold = 0, M =  5, train_rms:   0.90650, valid_rms:      0.90211\n",
      "Fold = 0, M =  6, train_rms:   0.88368, valid_rms:      0.87692\n",
      "Fold = 0, M =  7, train_rms:   0.88850, valid_rms:      0.88114\n",
      "Fold = 0, M =  8, train_rms:   0.87501, valid_rms:      0.86862\n",
      "Fold = 0, M =  9, train_rms:   0.87499, valid_rms:      0.88111\n",
      "Fold = 0, M = 10, train_rms:   0.86906, valid_rms:      0.86105\n",
      "Fold = 0, M = 11, train_rms:   0.86406, valid_rms:      0.86774\n",
      "Fold = 0, M = 12, train_rms:   0.86449, valid_rms:      0.86494\n",
      "Fold = 0, M = 13, train_rms:   0.86071, valid_rms:      0.86011\n",
      "Fold = 0, M = 14, train_rms:   0.85810, valid_rms:      4.71295\n",
      "Fold = 0, M = 15, train_rms:   0.85563, valid_rms:      4.03407\n",
      "Fold = 0, M = 16, train_rms:   0.85269, valid_rms:   3363.25024\n",
      "Fold = 0, M = 17, train_rms:   0.84704, valid_rms:   2819.54999\n",
      "Fold = 0, M = 18, train_rms:   0.84273, valid_rms:   4439.28902\n",
      "Fold = 0, M = 19, train_rms:   0.83920, valid_rms:   3906.48486\n",
      "Fold = 0, M = 20, train_rms:   5.13988, valid_rms: 236094.10735\n",
      "\n",
      "Fold = 1, M =  1, train_rms:   0.96160, valid_rms:      0.95185\n",
      "Fold = 1, M =  2, train_rms:   0.98257, valid_rms:      0.98605\n",
      "Fold = 1, M =  3, train_rms:   0.92944, valid_rms:      0.92406\n",
      "Fold = 1, M =  4, train_rms:   0.91755, valid_rms:      0.94278\n",
      "Fold = 1, M =  5, train_rms:   0.90434, valid_rms:      0.90976\n",
      "Fold = 1, M =  6, train_rms:   0.87767, valid_rms:      0.90293\n",
      "Fold = 1, M =  7, train_rms:   0.88394, valid_rms:      0.90092\n",
      "Fold = 1, M =  8, train_rms:   0.87004, valid_rms:      0.89280\n",
      "Fold = 1, M =  9, train_rms:   0.86980, valid_rms:      0.90094\n",
      "Fold = 1, M = 10, train_rms:   0.86259, valid_rms:      0.89042\n",
      "Fold = 1, M = 11, train_rms:   0.85696, valid_rms:      0.89689\n",
      "Fold = 1, M = 12, train_rms:   0.85757, valid_rms:      0.89500\n",
      "Fold = 1, M = 13, train_rms:   0.85343, valid_rms:      0.89087\n",
      "Fold = 1, M = 14, train_rms:   0.85030, valid_rms:     19.14862\n",
      "Fold = 1, M = 15, train_rms:   0.84758, valid_rms:     80.25730\n",
      "Fold = 1, M = 16, train_rms:   0.84285, valid_rms:  17628.84597\n",
      "Fold = 1, M = 17, train_rms:   0.84723, valid_rms:  33279.47381\n",
      "Fold = 1, M = 18, train_rms:   0.83314, valid_rms: 104836.49409\n",
      "Fold = 1, M = 19, train_rms:   0.86782, valid_rms:  58096.96479\n",
      "Fold = 1, M = 20, train_rms:   0.84779, valid_rms:  75532.86477\n",
      "\n",
      "Fold = 2, M =  1, train_rms:   0.95548, valid_rms:      0.97568\n",
      "Fold = 2, M =  2, train_rms:   0.98507, valid_rms:      0.98001\n",
      "Fold = 2, M =  3, train_rms:   0.92471, valid_rms:      0.94254\n",
      "Fold = 2, M =  4, train_rms:   0.92490, valid_rms:      0.92423\n",
      "Fold = 2, M =  5, train_rms:   0.90347, valid_rms:      0.92036\n",
      "Fold = 2, M =  6, train_rms:   0.88064, valid_rms:      0.89554\n",
      "Fold = 2, M =  7, train_rms:   0.88348, valid_rms:      0.90449\n",
      "Fold = 2, M =  8, train_rms:   0.86956, valid_rms:      0.89380\n",
      "Fold = 2, M =  9, train_rms:   0.87551, valid_rms:      0.88252\n",
      "Fold = 2, M = 10, train_rms:   0.86235, valid_rms:      0.89552\n",
      "Fold = 2, M = 11, train_rms:   0.86199, valid_rms:      0.88819\n",
      "Fold = 2, M = 12, train_rms:   0.86057, valid_rms:      0.89092\n",
      "Fold = 2, M = 13, train_rms:   0.85519, valid_rms:      0.89391\n",
      "Fold = 2, M = 14, train_rms:   0.85332, valid_rms:     20.33935\n",
      "Fold = 2, M = 15, train_rms:   0.85302, valid_rms:     42.16960\n",
      "Fold = 2, M = 16, train_rms:   0.84989, valid_rms:   2412.15083\n",
      "Fold = 2, M = 17, train_rms:   0.92612, valid_rms:  31108.68737\n",
      "Fold = 2, M = 18, train_rms:   0.84307, valid_rms:  46743.65033\n",
      "Fold = 2, M = 19, train_rms:   0.85871, valid_rms:  90007.72399\n",
      "Fold = 2, M = 20, train_rms:   0.84031, valid_rms: 193380.37135\n",
      "\n",
      "Fold = 3, M =  1, train_rms:   0.95949, valid_rms:      0.95668\n",
      "Fold = 3, M =  2, train_rms:   0.98248, valid_rms:      0.98819\n",
      "Fold = 3, M =  3, train_rms:   0.92699, valid_rms:      0.92810\n",
      "Fold = 3, M =  4, train_rms:   0.91779, valid_rms:      0.94211\n",
      "Fold = 3, M =  5, train_rms:   0.90351, valid_rms:      0.91005\n",
      "Fold = 3, M =  6, train_rms:   0.87758, valid_rms:      0.89905\n",
      "Fold = 3, M =  7, train_rms:   0.88293, valid_rms:      0.89721\n",
      "Fold = 3, M =  8, train_rms:   0.86983, valid_rms:      0.88582\n",
      "Fold = 3, M =  9, train_rms:   0.87017, valid_rms:      0.89499\n",
      "Fold = 3, M = 10, train_rms:   0.86370, valid_rms:      0.87732\n",
      "Fold = 3, M = 11, train_rms:   0.85812, valid_rms:      0.88409\n",
      "Fold = 3, M = 12, train_rms:   0.85853, valid_rms:      0.88358\n",
      "Fold = 3, M = 13, train_rms:   0.85438, valid_rms:      0.87980\n",
      "Fold = 3, M = 14, train_rms:   0.85133, valid_rms:     45.20021\n",
      "Fold = 3, M = 15, train_rms:   0.84978, valid_rms:     29.65273\n",
      "Fold = 3, M = 16, train_rms:   0.84457, valid_rms:   1314.61251\n",
      "Fold = 3, M = 17, train_rms:   0.84039, valid_rms:  76179.26295\n",
      "Fold = 3, M = 18, train_rms:   0.83668, valid_rms: 221838.38775\n",
      "Fold = 3, M = 19, train_rms:   0.83777, valid_rms:  53186.04450\n",
      "Fold = 3, M = 20, train_rms:   0.85107, valid_rms: 188812.25618\n",
      "\n",
      "Fold = 4, M =  1, train_rms:   0.95802, valid_rms:      0.96355\n",
      "Fold = 4, M =  2, train_rms:   0.98420, valid_rms:      0.98023\n",
      "Fold = 4, M =  3, train_rms:   0.92657, valid_rms:      0.93376\n",
      "Fold = 4, M =  4, train_rms:   0.92563, valid_rms:      0.91418\n",
      "Fold = 4, M =  5, train_rms:   0.90444, valid_rms:      0.90694\n",
      "Fold = 4, M =  6, train_rms:   0.88422, valid_rms:      0.87720\n",
      "Fold = 4, M =  7, train_rms:   0.88698, valid_rms:      0.88632\n",
      "Fold = 4, M =  8, train_rms:   0.87370, valid_rms:      0.87624\n",
      "Fold = 4, M =  9, train_rms:   0.87747, valid_rms:      0.87108\n",
      "Fold = 4, M = 10, train_rms:   0.86579, valid_rms:      0.87595\n",
      "Fold = 4, M = 11, train_rms:   0.86454, valid_rms:      0.86715\n",
      "Fold = 4, M = 12, train_rms:   0.86358, valid_rms:      0.86977\n",
      "Fold = 4, M = 13, train_rms:   0.85834, valid_rms:      0.87121\n",
      "Fold = 4, M = 14, train_rms:   0.85663, valid_rms:      1.81110\n",
      "Fold = 4, M = 15, train_rms:   0.85503, valid_rms:     17.10808\n",
      "Fold = 4, M = 16, train_rms:   0.85078, valid_rms:    398.16723\n",
      "Fold = 4, M = 17, train_rms:   0.84701, valid_rms:  21207.31205\n",
      "Fold = 4, M = 18, train_rms:   0.84301, valid_rms:  36028.76683\n",
      "Fold = 4, M = 19, train_rms:   0.84017, valid_rms:  31253.34101\n",
      "Fold = 4, M = 20, train_rms:   0.94297, valid_rms: 109723.05547\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fold_idx, fold in enumerate(n_folds):\n",
    "    train_x_i, valid_x_i, train_t_i, valid_t_i = fold[0], fold[1], fold[2], fold[3]\n",
    "    \n",
    "    for m in range(1, 21):\n",
    "        ## Train\n",
    "        model = RegressionModel(train_x.shape[1], M=m, basis=\"gaussian\")\n",
    "        w = model.train(train_x_i, train_t_i)\n",
    "        \n",
    "        ## Evaluate RMS error on training set\n",
    "        train_rms = model.eval_rms(train_x_i, w, train_t_i)\n",
    "        \n",
    "        ## Evaluate RMS error on validation set\n",
    "        valid_rms = model.eval_rms(valid_x_i, w, valid_t_i)\n",
    "        \n",
    "        print(\"Fold = {}, M = {:2d}, train_rms: {:9.5f}, valid_rms: {:12.5f}\".format(fold_idx, m, train_rms, valid_rms))\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Maximum A Posterior Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.3.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M =  1, train_rms:   0.95876, valid_rms:   0.96147\n",
      "M =  2, train_rms:   0.98351, valid_rms:   0.98325\n",
      "M =  3, train_rms:   0.92702, valid_rms:   0.93159\n",
      "M =  4, train_rms:   0.92522, valid_rms:   0.91183\n",
      "M =  5, train_rms:   0.90463, valid_rms:   0.90941\n",
      "M =  6, train_rms:   0.88238, valid_rms:   0.87905\n",
      "M =  7, train_rms:   0.88527, valid_rms:   0.89028\n",
      "M =  8, train_rms:   0.87205, valid_rms:   0.87643\n",
      "M =  9, train_rms:   0.87575, valid_rms:   0.87266\n",
      "M = 10, train_rms:   0.86510, valid_rms:   0.87303\n",
      "M = 11, train_rms:   0.86259, valid_rms:   0.86671\n",
      "M = 12, train_rms:   0.86212, valid_rms:   0.86906\n",
      "M = 13, train_rms:   0.85737, valid_rms:   0.86629\n",
      "M = 14, train_rms:   0.85475, valid_rms:   0.87559\n",
      "M = 15, train_rms:   0.85409, valid_rms:   0.96351\n",
      "M = 16, train_rms:   0.85023, valid_rms:   2.17879\n",
      "M = 17, train_rms:   0.84595, valid_rms:   2.10646\n",
      "M = 18, train_rms:   0.84205, valid_rms:   1.33886\n",
      "M = 19, train_rms:   0.83848, valid_rms:   1.02324\n",
      "M = 20, train_rms:   0.83549, valid_rms:   0.91889\n"
     ]
    }
   ],
   "source": [
    "## M = 1 ~ 20\n",
    "for m in range(1, 21):\n",
    "    model = RegressionModel(train_x.shape[1], m, basis=\"gaussian\", regularize=True, _lambda=0.0001)\n",
    "    w = model.train(train_x, train_t)\n",
    "    \n",
    "    ## Evaluate RMS error on training set\n",
    "    train_rms = model.eval_rms(train_x, w, train_t)\n",
    "    \n",
    "    ## Evaluate RMS error on validation set\n",
    "    valid_rms = model.eval_rms(valid_x, w, valid_t)\n",
    "    \n",
    "    print(\"M = {:2d}, train_rms: {:9.5f}, valid_rms: {:9.5f}\".format(m, train_rms, valid_rms))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b445ccfa557170e9a1397e58540c0ba15a3370c0d87db55f340afe85843e37a4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
